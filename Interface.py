import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import requests
from bs4 import BeautifulSoup
from konlpy.tag import Okt
from fpdf import FPDF
import time
import torch
from transformers import ElectraForSequenceClassification, ElectraTokenizer
import google.generativeai as genai
import os
from dotenv import load_dotenv
from datetime import datetime
import re

# Load environment variables from .env file
load_dotenv()

# --- ë‰´ìŠ¤ ê¸°ì‚¬ ìŠ¤í¬ë˜í•‘ ëª¨ë“ˆ í†µí•© ---
def scrape_article(url):
    try:
        res = requests.get(url, headers={"User-Agent": "Mozilla/5.0"}, timeout=5)
        if res.status_code != 200:
            return None
        soup = BeautifulSoup(res.text, "html.parser")
        title = soup.select_one("#news_title02")
        body = soup.select_one("#news_content")
        date = soup.select_one("#news_util01")
        return {
            "url": url,
            "title": title.get_text(strip=True) if title else "ì œëª© ì—†ìŒ",
            "date": date.get_text(strip=True) if date else datetime.now().strftime("%Y-%m-%d"),
            "content": body.get_text("\n", strip=True) if body else "ë‚´ìš© ì—†ìŒ",
        }
    except Exception:
        return None

def scrape_boannews_by_idx(start_idx, end_idx):
    articles = []
    missing_idx = []
    for idx in range(start_idx, end_idx + 1):
        url = f"https://www.boannews.com/media/view.asp?idx={idx}"
        article_data = scrape_article(url)
        if article_data:
            articles.append(article_data)
        else:
            missing_idx.append(idx)
        time.sleep(0.1)
    return articles, missing_idx

# --- 1. KoELECTRA ëª¨ë¸ ë¡œë”© (ê°€ìƒ í•¨ìˆ˜) ---
@st.cache_resource
def load_koelectra_model():
    model_name = "monologg/koelectra-base-v3-discriminator"
    tokenizer = ElectraTokenizer.from_pretrained(model_name)
    model = ElectraForSequenceClassification.from_pretrained(model_name, num_labels=5)
    # ì‹¤ì œ í•™ìŠµëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.
    # model.load_state_dict(torch.load("path/to/your/model.pt"))
    return tokenizer, model

# --- 2. Gemini API ì„¤ì • ---
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if not GEMINI_API_KEY:
    st.error("Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()
    
genai.configure(api_key=GEMINI_API_KEY)
generation_config = {
    "temperature": 0.7,
    "max_output_tokens": 1000,
}
gemini_model = genai.GenerativeModel('gemini-1.5-flash', generation_config=generation_config)

# --- 3. ë°ì´í„° ì „ì²˜ë¦¬ ëª¨ë“ˆ (ê°€ìƒ í•¨ìˆ˜) ---
@st.cache_data
def preprocess_text(text):
    okt = Okt()
    preprocessed = [token for token, pos in okt.pos(text, norm=True, stem=True)
                    if pos in ['Noun', 'Verb', 'Adjective']]
    return " ".join(preprocessed)

# --- 4. KoELECTRA ê¸°ë°˜ í‚¤ì›Œë“œ/ìœ„í—˜ë„ ë¶„ì„ (ê°€ìƒ í•¨ìˆ˜ -> í‚¤ì›Œë“œ ê¸°ë°˜ ë¡œì§ìœ¼ë¡œ ëŒ€ì²´) ---
def analyze_risk_with_model(text):
    risk_keywords_map = {
        "ATTACK": {
            "ëœì„¬ì›¨ì–´": 1.0, "ì œë¡œë°ì´": 1.0, "í”¼ì‹±": 0.9, "DDoS": 0.8, "ì•…ì„±ì½”ë“œ": 0.9,
            "í•´í‚¹": 0.9, "ê³µê²©": 0.8, "ì¹¨í•´": 0.8, "ìœ ì¶œ": 0.8, "íƒˆì·¨": 0.8
        },
        "VULN": {
            "ì·¨ì•½ì ": 1.0, "CVE": 1.0, "ë²„ê·¸": 0.9, "ê²°í•¨": 0.9, "ë³´ì•ˆ ê²°í•¨": 1.0
        },
        "ORG": {
            "ë§ˆì´í¬ë¡œì†Œí”„íŠ¸": 0.3, "êµ¬ê¸€": 0.3, "ì‚¼ì„±": 0.2, "ì• í”Œ": 0.2, "ì •ë¶€": 0.1,
            "ê¸°ì—…": 0.1, "ê¸°ê´€": 0.1, "ëŒ€í•™êµ": 0.1
        },
        "STRATEGY": {
            "ì œë¡œ íŠ¸ëŸ¬ìŠ¤íŠ¸": 0.7, "ë°©í™”ë²½": 0.6, "íŒ¨ì¹˜": 0.6, "ë°±ì—…": 0.5, "ì¸ì¦": 0.4,
            "ëª¨ë‹ˆí„°ë§": 0.5, "ì •ì±…": 0.4
        }
    }
    
    extracted_keywords = []
    total_score = 0
    
    for category, keywords in risk_keywords_map.items():
        for keyword, score in keywords.items():
            if re.search(r'\b' + re.escape(keyword) + r'\b', text, re.I):
                extracted_keywords.append(keyword)
                total_score += score
    
    extracted_keywords = list(set(extracted_keywords))
    if total_score >= 2.0:
        risk_level = "ë†’ìŒ"
    elif total_score >= 0.8:
        risk_level = "ì¤‘ê°„"
    else:
        risk_level = "ë‚®ìŒ"
    
    return risk_level, extracted_keywords, total_score

# --- 5. LLM ê¸°ë°˜ ëŒ€ì‘ ë°©ì•ˆ ìƒì„± (ìˆ˜ì •) ---
def generate_playbook_with_llm(keywords, company_info, playbook_detail, infrastructure, constraints):
    prompt = f"""
    ë‹¹ì‹ ì€ ì¤‘ì†Œê¸°ì—…ì„ ìœ„í•œ ë³´ì•ˆ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë§ì¶¤í˜• ë³´ì•ˆ ëŒ€ì‘ í”Œë ˆì´ë¶ì„ ìƒì„±í•´ì£¼ì„¸ìš”.
    - ê¸°ì—…ëª…: {company_info['name']}
    - ê¸°ì—… ê·œëª¨: {company_info['size']}
    - ì—…ì¢…: {company_info['industry']}
    - ì¸í”„ë¼ í™˜ê²½: {infrastructure}
    - ì£¼ìš” ìœ„í˜‘ í‚¤ì›Œë“œ: {', '.join(keywords)}
    - ìƒì„¸ë„ ìˆ˜ì¤€: {playbook_detail}
    - ê³ ë ¤í•´ì•¼ í•  ì œí•œì‚¬í•­: {constraints}

    ìœ„í˜‘ì— ëŒ€í•œ ì¦‰ì‹œ ëŒ€ì‘ ì¡°ì¹˜ì™€ ì¤‘ì¥ê¸° ëŒ€ì‘ ë°©ì•ˆì„ í¬í•¨í•˜ê³ , ì´í•´í•˜ê¸° ì‰¬ìš´ ì²´í¬ë¦¬ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”.
    """
    try:
        response = genai.GenerativeModel('gemini-1.5-flash').generate_content(prompt)
        return response.text
    except Exception as e:
        st.error(f"Gemini API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        return "í”Œë ˆì´ë¶ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."

# --- 6. PDF ë³´ê³ ì„œ ìƒì„± ëª¨ë“ˆ ---
def create_pdf_report(report_data):
    pdf = FPDF()
    pdf.set_auto_page_break(auto=True, margin=15)
    pdf.add_page()
    
    pdf.add_font('NanumGothic', '', 'font/NanumGothic.ttf', uni=True)
    pdf.add_font('NanumGothicBold', '', 'font/NanumGothicBold.ttf', uni=True)

    pdf.set_font('NanumGothicBold', '', 20)
    pdf.cell(0, 10, 'ì¤‘ì†Œê¸°ì—… ë³´ì•ˆ ìœ„í—˜ ë¶„ì„ ë³´ê³ ì„œ', 0, 1, 'C')
    pdf.ln(10)

    pdf.set_font('NanumGothicBold', '', 14)
    pdf.cell(0, 10, '1. ìš”ì•½ ì •ë³´', 0, 1)
    pdf.set_font('NanumGothic', '', 12)
    pdf.multi_cell(0, 7, report_data['summary'])
    pdf.ln(5)

    pdf.set_font('NanumGothicBold', '', 14)
    pdf.cell(0, 10, '2. ì£¼ìš” ìœ„í—˜ í‚¤ì›Œë“œ', 0, 1)
    pdf.set_font('NanumGothic', '', 12)
    for kw in report_data['keywords']:
        pdf.multi_cell(0, 7, f"- {kw['keyword']}: {kw['risk_level']} (ë¹ˆë„: {kw['frequency']})")
    pdf.ln(5)
    
    pdf.set_font('NanumGothicBold', '', 14)
    pdf.cell(0, 10, '3. AI ìƒì„± ëŒ€ì‘ í”Œë ˆì´ë¶', 0, 1)
    pdf.set_font('NanumGothic', '', 12)
    pdf.multi_cell(0, 7, report_data['playbook'])
    
    pdf_output = pdf.output(dest='S').encode('latin1')
    return pdf_output

# --- Streamlit UI êµ¬ì„± ---
st.set_page_config(
    page_title="ì¤‘ì†Œê¸°ì—… ë³´ì•ˆ ìœ„í—˜ ë¶„ì„ ì‹œìŠ¤í…œ",
    page_icon="ğŸ›¡ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 10px;
        margin-bottom: 2rem;
        color: white;
        text-align: center;
    }
    .metric-card {
        background: white;
        padding: 1.5rem;
        border-radius: 10px;
        box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        border-left: 4px solid #667eea;
        margin-bottom: 1rem;
    }
    .risk-high { border-left-color: #e74c3c !important; background: linear-gradient(135deg, #fff5f5 0%, #fed7d7 100%); }
    .risk-medium { border-left-color: #f39c12 !important; background: linear-gradient(135deg, #fffbf0 0%, #feebc8 100%); }
    .risk-low { border-left-color: #27ae60 !important; background: linear-gradient(135deg, #f0fff4 0%, #c6f6d5 100%); }
    .news-item {
        background: white;
        padding: 1.5rem;
        border-radius: 8px;
        margin-bottom: 1rem;
        box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        border-left: 3px solid #3498db;
    }
    .recommendation-box {
        background: linear-gradient(135deg, #f8f9ff 0%, #e8f2ff 100%);
        padding: 2rem;
        border-radius: 10px;
        margin: 1rem 0;
        border: 1px solid #d4e6ff;
    }
    .sidebar-logo {
        text-align: center;
        padding: 1rem;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        border-radius: 10px;
        margin-bottom: 1rem;
        color: white;
    }
    .stSelectbox > div > div { background-color: #f8f9fa; }
    .stButton > button {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        border-radius: 5px;
        padding: 0.5rem 1rem;
        font-weight: 600;
        width: 100%;
    }
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(102, 126, 234, 0.4);
    }
</style>
""", unsafe_allow_html=True)

# --- ì‚¬ì´ë“œë°” ---
with st.sidebar:
    st.markdown("""
    <div class="sidebar-logo">
        <h2>ğŸ›¡ï¸ SecureWatch</h2>
        <p>ì¤‘ì†Œê¸°ì—… ë³´ì•ˆ ìœ„í—˜ ë¶„ì„</p>
    </div>
    """, unsafe_allow_html=True)
    
    st.subheader("ğŸ¢ ê¸°ì—… ì •ë³´ ì„¤ì •")
    company_name = st.text_input("íšŒì‚¬ëª…", value="ABC ì†Œí”„íŠ¸ì›¨ì–´")
    company_size = st.selectbox("ê¸°ì—… ê·œëª¨", ["ì†Œê·œëª¨ (10-50ëª…)", "ì¤‘ì†Œê·œëª¨ (50-200ëª…)", "ì¤‘ê·œëª¨ (200-500ëª…)"])
    industry_type = st.selectbox("ì—…ì¢…", ["IT/ì†Œí”„íŠ¸ì›¨ì–´", "ì œì¡°ì—…", "ê¸ˆìœµì—…", "ì˜ë£Œì—…", "êµìœ¡ì—…", "ê¸°íƒ€"])
    
    st.subheader("ğŸŒ ì¸í”„ë¼ ë° ì œì•½ì‚¬í•­")
    infrastructure = st.selectbox("ì¸í”„ë¼ í™˜ê²½", ["AWS", "Azure", "GCP", "On-premise", "Hybrid"])
    constraints = st.text_area("ë³´ì•ˆ ì •ì±…/ì˜ˆì‚° ë“± ì œí•œì‚¬í•­", value="ì›” ì˜ˆì‚° 50ë§Œì› ì´í•˜.")
    
    st.divider()
    
    st.subheader("âš™ï¸ ë¶„ì„ ì„¤ì •")
    risk_level_setting = st.selectbox("ìœ„í—˜ë„", ["ìƒ", "ì¤‘", "í•˜"], index=0)

    st.divider()
    
    if st.button("ğŸ” ë¶„ì„ ì‹œì‘", type="primary"):
        st.session_state.analysis_started = True
        st.session_state.news_data = []
        st.session_state.risk_keywords = []
        st.session_state.playbook_content = ""
        st.session_state.report_summary = ""

        with st.spinner("ìµœì‹  ë³´ì•ˆ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘ ë° ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            scraped_articles, missing_indices = scrape_boannews_by_idx(138700, 138770)
            
            st.session_state.all_articles = scraped_articles
            
            st.session_state.news_data = []
            keyword_counts = {}
            for news in scraped_articles:
                combined_text = news['title'] + " " + news['content']
                risk_level, keywords, risk_score = analyze_risk_with_model(combined_text)
                
                for kw in keywords:
                    keyword_counts[kw] = keyword_counts.get(kw, 0) + 1
                
                news_item = {
                    "title": news['title'],
                    "summary": news['content'][:150] + "..." if len(news['content']) > 150 else news['content'],
                    "source": "ë³´ì•ˆë‰´ìŠ¤",
                    "published": news['date'],
                    "risk_score": risk_score,
                    "keywords": keywords,
                    "risk_level": risk_level,
                    "url": news['url'] # url ì¶”ê°€
                }
                st.session_state.news_data.append(news_item)
            
            st.session_state.risk_keywords = [
                {"keyword": kw, "frequency": count, "risk_level": analyze_risk_with_model(kw)[0]}
                for kw, count in keyword_counts.items()
            ]

        st.session_state.playbook_content = generate_playbook_with_llm(
            list(keyword_counts.keys()),
            {"name": company_name, "size": company_size, "industry": industry_type},
            risk_level_setting,
            infrastructure,
            constraints
        )
        st.session_state.report_summary = f"ì´ {len(st.session_state.news_data)}ê°œì˜ ë‰´ìŠ¤ë¥¼ ìŠ¤í¬ë˜í•‘í•˜ê³  ë¶„ì„í–ˆìŠµë‹ˆë‹¤."
        
        st.success("âœ… ë¶„ì„ ì™„ë£Œ! ì•„ë˜ íƒ­ì—ì„œ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        st.rerun()

# ë©”ì¸ í—¤ë”
st.markdown("""
<div class="main-header">
    <h1>ğŸ›¡ï¸ ì¤‘ì†Œê¸°ì—… ë³´ì•ˆ ìœ„í—˜ ë¶„ì„ ì‹œìŠ¤í…œ</h1>
    <p>AI ê¸°ë°˜ ìµœì‹  ë³´ì•ˆ ìœ„í˜‘ ë¶„ì„ ë° ë§ì¶¤í˜• ëŒ€ì‘ ë°©ì•ˆ ì œê³µ</p>
</div>
""", unsafe_allow_html=True)

# ë©”ì¸ íƒ­ êµ¬ì„±
tab1, tab2, tab3, tab4, tab5 = st.tabs(["ğŸ“Š ëŒ€ì‹œë³´ë“œ", "ğŸ“° ë‰´ìŠ¤ ë¶„ì„", "ğŸ¯ ìœ„í—˜ í‚¤ì›Œë“œ", "ğŸ“‹ ëŒ€ì‘ í”Œë ˆì´ë¶", "ğŸ“„ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ"])

# --- ëŒ€ì‹œë³´ë“œ íƒ­ ---
with tab1:
    st.header("ğŸ“Š ë³´ì•ˆ ìœ„í—˜ ëŒ€ì‹œë³´ë“œ")
    if 'analysis_started' not in st.session_state:
        st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ ê¸°ì—… ì •ë³´ë¥¼ ì„¤ì •í•˜ê³  'ë¶„ì„ ì‹œì‘' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
    else:
        col1, col2, col3, col4 = st.columns(4)
        high_risk_count = sum(1 for news in st.session_state.news_data if news['risk_level'] == "ë†’ìŒ")
        medium_risk_count = sum(1 for news in st.session_state.news_data if news['risk_level'] == "ì¤‘ê°„")
        with col1:
            st.markdown(f"""<div class="metric-card"><h3 style="color: #667eea; margin: 0;">ğŸ“° ìˆ˜ì§‘ëœ ë‰´ìŠ¤</h3><h2 style="margin: 0.5rem 0;">{len(st.session_state.news_data)}</h2><p style="color: #666; margin: 0;">ì´ ê¸°ì‚¬ ìˆ˜</p></div>""", unsafe_allow_html=True)
        with col2:
            st.markdown(f"""<div class="metric-card risk-high"><h3 style="color: #e74c3c; margin: 0;">âš ï¸ ê³ ìœ„í—˜ ì•Œë¦¼</h3><h2 style="margin: 0.5rem 0;">{high_risk_count}</h2><p style="color: #666; margin: 0;">(í‚¤ì›Œë“œ ê¸°ë°˜)</p></div>""", unsafe_allow_html=True)
        with col3:
            st.markdown(f"""<div class="metric-card risk-medium"><h3 style="color: #f39c12; margin: 0;">ğŸ”¶ ì¤‘ìœ„í—˜ ì•Œë¦¼</h3><h2 style="margin: 0.5rem 0;">{medium_risk_count}</h2><p style="color: #666; margin: 0;">(í‚¤ì›Œë“œ ê¸°ë°˜)</p></div>""", unsafe_allow_html=True)
        with col4:
            st.markdown(f"""<div class="metric-card"><h3 style="color: #2c3e50; margin: 0;">ğŸ“ˆ ë¶„ì„ í‚¤ì›Œë“œ</h3><h2 style="margin: 0.5rem 0;">{len(st.session_state.risk_keywords)}</h2><p style="color: #666; margin: 0;">(ê³ ìœ  í‚¤ì›Œë“œ ìˆ˜)</p></div>""", unsafe_allow_html=True)

        st.divider()
        col1, col2 = st.columns(2)
        with col1:
            st.subheader("ğŸ“ˆ ìœ„í—˜ë„ ë“±ê¸‰ë³„ ë‰´ìŠ¤ ë¶„í¬")
            if st.session_state.news_data:
                df = pd.DataFrame(st.session_state.news_data)
                risk_counts = df['risk_level'].value_counts().reindex(['ë†’ìŒ', 'ì¤‘ê°„', 'ë‚®ìŒ'], fill_value=0)
                
                fig = px.bar(
                    x=risk_counts.index, 
                    y=risk_counts.values, 
                    labels={'x': 'ìœ„í—˜ë„ ë“±ê¸‰', 'y': 'ë‰´ìŠ¤ ê¸°ì‚¬ ìˆ˜'},
                    color=risk_counts.index,
                    color_discrete_map={"ë†’ìŒ": "#e74c3c", "ì¤‘ê°„": "#f39c12", "ë‚®ìŒ": "#27ae60"}
                )
                fig.update_layout(height=400, showlegend=False)
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.info("ë¶„ì„ëœ ë‰´ìŠ¤ê°€ ì—†ì–´ ìœ„í—˜ë„ ë¶„í¬ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        with col2:
            st.subheader("ğŸ¯ ìœ„í—˜ í‚¤ì›Œë“œ ë¶„í¬")
            if st.session_state.risk_keywords:
                keywords_df = pd.DataFrame(st.session_state.risk_keywords)
                keywords_df['risk_color'] = keywords_df['risk_level'].map({'ë†’ìŒ': '#e74c3c', 'ì¤‘ê°„': '#f39c12', 'ë‚®ìŒ': '#27ae60'})
                
                fig = go.Figure(data=[go.Pie(
                    labels=keywords_df['keyword'], 
                    values=keywords_df['frequency'], 
                    hole=.5,
                    marker=dict(colors=keywords_df['risk_color']),
                    hovertemplate='<b>%{label}</b><br>ë¹ˆë„: %{value}<br>ìœ„í—˜ë„: %{customdata}',
                    customdata=keywords_df['risk_level']
                )])
                fig.update_layout(height=400, showlegend=True, margin=dict(t=0, b=0, l=0, r=0))
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.warning("ë¶„ì„ëœ ìœ„í—˜ í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")

# --- ë‰´ìŠ¤ ë¶„ì„ íƒ­ ---
with tab2:
    st.header("ğŸ“° ìµœì‹  ë³´ì•ˆ ë‰´ìŠ¤ ë¶„ì„")
    if 'analysis_started' not in st.session_state:
        st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ 'ë¶„ì„ ì‹œì‘' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
    else:
        page_size = 10
        total_articles = len(st.session_state.news_data)
        total_pages = (total_articles - 1) // page_size + 1 if total_articles > 0 else 1

        if 'current_page' not in st.session_state:
            st.session_state.current_page = 1
        
        start_idx = (st.session_state.current_page - 1) * page_size
        end_idx = start_idx + page_size
        paged_news_data = st.session_state.news_data[start_idx:end_idx]
        
        st.divider()

        if not paged_news_data:
            st.info("ì„ íƒí•œ í•„í„°ì— í•´ë‹¹í•˜ëŠ” ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            for news in paged_news_data:
                risk_class = "risk-high" if news["risk_level"] == "ë†’ìŒ" else "risk-medium" if news["risk_level"] == "ì¤‘ê°„" else "risk-low"
                
                # ë‰´ìŠ¤ ì œëª©ì— í•˜ì´í¼ë§í¬ ì¶”ê°€
                st.markdown(f"""
                <div class="news-item {risk_class}">
                    <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 1rem;">
                        <h3 style="margin: 0; color: #2c3e50;"><a href="{news['url']}" target="_blank">{news['title']}</a></h3>
                        <span style="background: {'#e74c3c' if news['risk_level'] == 'ë†’ìŒ' else '#f39c12' if news['risk_level'] == 'ì¤‘ê°„' else '#27ae60'}; color: white; padding: 0.3rem 0.8rem; border-radius: 15px; font-size: 0.8rem; font-weight: bold;">
                            ìœ„í—˜ë„: {news['risk_level']} ({news['risk_score']:.2f})
                        </span>
                    </div>
                    <p style="color: #555; margin-bottom: 1rem;">{news['summary']}</p>
                    <div style="display: flex; justify-content: space-between; align-items: center;">
                        <div>
                            <strong>í‚¤ì›Œë“œ:</strong> {', '.join(news['keywords'])}
                        </div>
                        <div style="color: #888; font-size: 0.9rem;">
                            {news['source']} | {news['published']}
                        </div>
                    </div>
                </div>
                """, unsafe_allow_html=True)
                
                with st.expander("ğŸ” AI ë¶„ì„ ê²°ê³¼"):
                    st.markdown(f"""
                    **ìœ„í—˜ ë¶„ì„:**- ì´ ë‰´ìŠ¤ëŠ” **{news['risk_level']} ìœ„í—˜**ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. (í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„)- ì£¼ìš” ìœ„í—˜ ìš”ì†Œ: {', '.join(news['keywords'][:2])}- ì´ ë¶„ì„ì€ í‚¤ì›Œë“œ ì ìˆ˜í‘œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤.
                    """)
        
        st.divider()
        col1, col2, col3, col4, col5 = st.columns(5)
        with col1:
            if st.button("<< ì²˜ìŒ"): st.session_state.current_page = 1
        with col2:
            if st.button("< ì´ì „", disabled=st.session_state.current_page == 1): st.session_state.current_page -= 1
        with col4:
            if st.button("ë‹¤ìŒ >", disabled=st.session_state.current_page == total_pages): st.session_state.current_page += 1
        with col5:
            if st.button("ë§ˆì§€ë§‰ >>"): st.session_state.current_page = total_pages
        with col3:
            st.markdown(f"<p style='text-align:center; font-weight:bold;'>{st.session_state.current_page} / {total_pages}</p>", unsafe_allow_html=True)

# --- ìœ„í—˜ í‚¤ì›Œë“œ íƒ­ ---
with tab3:
    st.header("ğŸ¯ AI ì¶”ì¶œ ìœ„í—˜ í‚¤ì›Œë“œ")
    if 'analysis_started' not in st.session_state:
        st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ 'ë¶„ì„ ì‹œì‘' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
    else:
        st.subheader("ğŸ“Š ì‹¤ì‹œê°„ í†µê³„")
        col1, col2 = st.columns(2)
        high_risk_kw = sum(1 for kw in st.session_state.risk_keywords if kw['risk_level'] == 'ë†’ìŒ')
        with col1:
            st.metric("ì´ ì¶”ì¶œ í‚¤ì›Œë“œ", f"{len(st.session_state.risk_keywords)}ê°œ")
        with col2:
            st.metric("ê³ ìœ„í—˜ í‚¤ì›Œë“œ", f"{high_risk_kw}ê°œ")
        st.divider()
        def get_risk_color(risk_level):
            colors = {"ë†’ìŒ": "ğŸ”´", "ì¤‘ê°„": "ğŸŸ¡", "ë‚®ìŒ": "ğŸŸ¢"}
            return colors.get(risk_level, "âšª")
        st.subheader("ğŸ” ì¶”ì¶œëœ ìœ„í—˜ í‚¤ì›Œë“œ")
        for idx, kw in enumerate(st.session_state.risk_keywords):
            col1, col2, col3 = st.columns([3, 1, 1])
            with col1: st.markdown(f"**{kw['keyword']}** {get_risk_color(kw['risk_level'])}")
            with col2: st.markdown(f"ë¹ˆë„: **{kw['frequency']}**")
            with col3: st.markdown(f"ìœ„í—˜ë„: **{kw['risk_level']}**")

# --- ëŒ€ì‘ í”Œë ˆì´ë¶ íƒ­ ---
with tab4:
    st.header("ğŸ“‹ AI ìƒì„± ëŒ€ì‘ í”Œë ˆì´ë¶")
    if 'analysis_started' not in st.session_state:
        st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ 'ë¶„ì„ ì‹œì‘' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
    else:
        st.markdown(f"""<div class="recommendation-box"><h3>ğŸ›¡ï¸ ë§ì¶¤í˜• ëŒ€ì‘ í”Œë ˆì´ë¶</h3><p style="white-space: pre-wrap;">{st.session_state.playbook_content}</p></div>""", unsafe_allow_html=True)
        
# --- ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ íƒ­ ---
with tab5:
    st.header("ğŸ“„ ë¶„ì„ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ")
    if 'analysis_started' not in st.session_state:
        st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ 'ë¶„ì„ ì‹œì‘' ë²„íŠ¼ì„ ëˆŒëŸ¬ ë³´ê³ ì„œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")
    else:
        st.write("ë¶„ì„ ê²°ê³¼ë¥¼ PDF ë³´ê³ ì„œë¡œ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        report_data = {
            "summary": st.session_state.report_summary,
            "keywords": st.session_state.risk_keywords,
            "playbook": st.session_state.playbook_content
        }
        pdf_output = create_pdf_report(report_data)
        st.download_button(label="ğŸ“„ PDF ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ", data=pdf_output, file_name=f"ë³´ì•ˆ_ìœ„í—˜_ë¶„ì„_ë³´ê³ ì„œ_{company_name}.pdf", mime="application/pdf")

# í•˜ë‹¨ ì •ë³´
st.divider()
st.markdown("""<div style="text-align: center; color: #888; padding: 2rem;"><p>ğŸ›¡ï¸ SecureWatch - ì¤‘ì†Œê¸°ì—… ë³´ì•ˆ ìœ„í—˜ ë¶„ì„ ì‹œìŠ¤í…œ</p><p>AI ê¸°ë°˜ ì‹¤ì‹œê°„ ë³´ì•ˆ ìœ„í˜‘ ë¶„ì„ ë° ëŒ€ì‘ ë°©ì•ˆ ì œê³µ | Made by íŒ”ìƒ‰ì¡°</p></div>""", unsafe_allow_html=True)